{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 | 面向对象（下）：如何实现一个搜索引擎？\n",
    "\n",
    "### “高大上”的搜索引擎\n",
    "\n",
    "一个搜索引擎由搜索器、索引器、检索器和用户接口四个部分组成。\n",
    "\n",
    "- 搜索器，通俗来讲就是我们常提到的爬虫（scrawler），它能在互联网上大量爬取各类网站的内容，送给索引器。\n",
    "- 索引器拿到网页和内容后，会对内容进行处理，形成索引（index），存储于内部的数据库等待检索。\n",
    "- 最后的用户接口很好理解，是指网页和 App 前端界面，例如百度和谷歌的搜索页面。用户通过用户接口，向搜索引擎发出询问（query），询问解析后送达检索器；\n",
    "- 检索器高效检索后，再将结果返回给用户。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先来定义 SearchEngineBase 基类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngineBase(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def add_corpus(self, file_path):\n",
    "        with open(file_path, 'r') as fin:\n",
    "            text = fin.read()\n",
    "        self.process_corpus(file_path, text)\n",
    "\n",
    "    def process_corpus(self, id, text):\n",
    "        raise Exception('process_corpus not implemented.')\n",
    "\n",
    "    def search(self, query):\n",
    "        raise Exception('search not implemented.')\n",
    "\n",
    "def main(search_engine):\n",
    "    for file_path in ['1.txt', '2.txt', '3.txt', '4.txt', '5.txt']:\n",
    "        search_engine.add_corpus('./input/'+file_path)\n",
    "\n",
    "    while True:\n",
    "        query = input()\n",
    "        if query == 'exit':\n",
    "            break\n",
    "            \n",
    "        results = search_engine.search(query)\n",
    "        print('found {} result(s):'.format(len(results)))\n",
    "        for result in results:\n",
    "            print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SearchEngineBase 可以被继承，继承的类分别代表不同的算法引擎。\n",
    "- 每一个引擎都应该实现 process_corpus() 和 search() 两个函数，对应我们刚刚提到的索引器和检索器。\n",
    "- main() 函数提供搜索器和用户接口，于是一个简单的包装界面就有了。\n",
    "\n",
    "具体来看这段代码，其中，\n",
    "- add_corpus() 函数负责读取文件内容，将文件路径作为 ID，连同内容一起送到 process_corpus 中。\n",
    "- process_corpus 需要对内容进行处理，然后文件路径为 ID ，将处理后的内容存下来。处理后的内容，就叫做索引（index）。\n",
    "- search 则给定一个询问，处理询问，再通过索引检索，然后返回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEngine(SearchEngineBase):\n",
    "    def __init__(self):\n",
    "        super(SimpleEngine, self).__init__()\n",
    "        self.__id_to_texts = {}\n",
    "\n",
    "    def process_corpus(self, id, text):\n",
    "        self.__id_to_texts[id] = text\n",
    "\n",
    "    def search(self, query):\n",
    "        results = []\n",
    "        for id, text in self.__id_to_texts.items():\n",
    "            if query in text:\n",
    "                results.append(id)\n",
    "        return results\n",
    "\n",
    "search_engine = SimpleEngine()\n",
    "main(search_engine)\n",
    "\n",
    "\n",
    "# ########## 输出 ##########\n",
    "\n",
    "\n",
    "# simple\n",
    "# found 0 result(s):\n",
    "# little\n",
    "# found 2 result(s):\n",
    "# 1.txt\n",
    "# 2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SimpleEngine 实现了一个继承 SearchEngineBase 的子类，继承并实现了 process_corpus 和 search 接口，同时，也顺手继承了 add_corpus 函数（当然你想重写也是可行的），因此我们可以在 main() 函数中直接调取。\n",
    "- 在我们新的构造函数中，self.__id_to_texts = {} 初始化了自己的私有变量，也就是这个用来存储文件名到文件内容的字典。process_corpus() 函数则非常直白地将文件内容插入到字典中。这里注意，ID 需要是唯一的，不然相同 ID 的新内容会覆盖掉旧的内容。\n",
    "- search 直接枚举字典，从中找到要搜索的字符串。如果能够找到，则将 ID 放到结果列表中，最后返回。\n",
    "\n",
    "\n",
    "这种实现方式简单，但显然是一种很低效的方式：\n",
    "- 每次索引后需要占用大量空间，因为索引函数并没有做任何事情；【<font color=blue>self.__id_to_texts的value是整个文档的text</font>】\n",
    "- 每次检索需要占用大量时间，因为所有索引库的文件都要被重新搜索一遍。如果把语料的信息量视为 n，那么这里的时间复杂度和空间复杂度都应该是 O(n) 级别的。\n",
    "- 这里的 query 只能是一个词，或者是连起来的几个词。如果你想要搜索多个词，它们又分散在文章的不同位置，我们的简单引擎就无能为力了。\n",
    "\n",
    "解决方案：\n",
    "最直接的一个想法，就是把语料分词，看成一个个的词汇，这样就只需要对每篇文章存储它所有词汇的 set 即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words 和 inverted index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have a dream\n",
      "found 3 result(s):\n",
      "./input/1.txt\n",
      "./input/2.txt\n",
      "./input/3.txt\n",
      "freedom children\n",
      "found 1 result(s):\n",
      "./input/5.txt\n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class BOWEngine(SearchEngineBase):\n",
    "    def __init__(self):\n",
    "        super(BOWEngine, self).__init__()\n",
    "        self.__id_to_words = {}\n",
    "\n",
    "    def process_corpus(self, id, text):\n",
    "        self.__id_to_words[id] = self.parse_text_to_words(text)\n",
    "\n",
    "    def search(self, query):\n",
    "        query_words = self.parse_text_to_words(query)\n",
    "        results = []\n",
    "        for id, words in self.__id_to_words.items():\n",
    "            if self.query_match(query_words, words):\n",
    "                results.append(id)\n",
    "        return results\n",
    "    \n",
    "    @staticmethod\n",
    "    def query_match(query_words, words):\n",
    "        for query_word in query_words:\n",
    "            if query_word not in words:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_text_to_words(text):\n",
    "        # 使用正则表达式去除标点符号和换行符\n",
    "        text = re.sub(r'[^\\w ]', ' ', text)\n",
    "        # 转为小写\n",
    "        text = text.lower()\n",
    "        # 生成所有单词的列表\n",
    "        word_list = text.split(' ')\n",
    "        # 去除空白单词\n",
    "        word_list = filter(None, word_list)\n",
    "        # 返回单词的 set\n",
    "        return set(word_list)\n",
    "\n",
    "search_engine = BOWEngine()\n",
    "main(search_engine)\n",
    "\n",
    "\n",
    "########## 输出 ##########\n",
    "\n",
    "\n",
    "# i have a dream\n",
    "# found 3 result(s):\n",
    "# 1.txt\n",
    "# 2.txt\n",
    "# 3.txt\n",
    "# freedom children\n",
    "# found 1 result(s):\n",
    "# 5.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先来理解一个概念，BOW Model\n",
    "\n",
    "1. 假设一个文本，不考虑语法、句法、段落，也不考虑词汇出现的顺序，只将这个文本看成这些词汇的集合。于是相应的，我们把 id_to_texts 替换成 id_to_words\n",
    "\n",
    "2. process_corpus() 函数调用类静态函数 parse_text_to_words，将文章打碎形成词袋，放入 set 之后再放到字典中\n",
    "\n",
    "3. search() 函数则稍微复杂一些。这里我们假设，想得到的结果，是所有的搜索关键词都要出现在同一篇文章中我们需要同样打碎 query 得到一个 set，然后把 set 中的每一个词，和我们的索引中每一篇文章进行核对，看一下要找的词是否在其中。而这个过程由静态函数 query_match 负责。\n",
    "\n",
    "注意：parse_text_to_words和query_match这两个函数都是没有状态的，**它们不涉及对象的私有变量**（没有 self 作为参数），相同的输入能够得到完全相同的输出结果。因此设置为静态，可以方便其他的类来使用。\n",
    "\n",
    "\n",
    "缺陷：\n",
    "1. 可是，即使这样做，每次查询时依然需要遍历所有 ID，虽然比起 Simple 模型已经节约了大量时间，但是互联网上有上亿个页面，每次都全部遍历的代价还是太大了\n",
    "2. 再有，词袋模型并不考虑单词间的顺序，但有些人希望单词按顺序出现，或者希望搜索的单词在文中离得近一些，这种情况下词袋模型现任就无能为力了。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "class BOWInvertedIndexEngine(SearchEngineBase):\n",
    "    def __init__(self):\n",
    "        super(BOWInvertedIndexEngine, self).__init__()\n",
    "        self.inverted_index = {}\n",
    "\n",
    "    def process_corpus(self, id, text):\n",
    "        words = self.parse_text_to_words(text)\n",
    "        for word in words:\n",
    "            if word not in self.inverted_index:\n",
    "                self.inverted_index[word] = []\n",
    "            self.inverted_index[word].append(id)\n",
    "\n",
    "    def search(self, query):\n",
    "        query_words = list(self.parse_text_to_words(query))\n",
    "        query_words_index = list()\n",
    "        for query_word in query_words:\n",
    "            query_words_index.append(0)\n",
    "        \n",
    "        # 如果某一个查询单词的倒序索引为空，我们就立刻返回\n",
    "        for query_word in query_words:\n",
    "            if query_word not in self.inverted_index:\n",
    "                return []\n",
    "        \n",
    "        result = []\n",
    "        while True:\n",
    "            \n",
    "            # 首先，获得当前状态下所有倒序索引的 index\n",
    "            current_ids = []\n",
    "            \n",
    "            for idx, query_word in enumerate(query_words):\n",
    "                current_index = query_words_index[idx]\n",
    "                current_inverted_list = self.inverted_index[query_word]\n",
    "                \n",
    "                # 已经遍历到了某一个倒序索引的末尾，结束 search\n",
    "                if current_index >= len(current_inverted_list):\n",
    "                    return result\n",
    "\n",
    "                current_ids.append(current_inverted_list[current_index])\n",
    "\n",
    "            # 然后，如果 current_ids 的所有元素都一样，那么表明这个单词在这个元素对应的文档中都出现了\n",
    "            if all(x == current_ids[0] for x in current_ids):\n",
    "                result.append(current_ids[0])\n",
    "                query_words_index = [x + 1 for x in query_words_index]\n",
    "                continue\n",
    "            \n",
    "            # 如果不是，我们就把最小的元素加一\n",
    "            min_val = min(current_ids)\n",
    "            min_val_pos = current_ids.index(min_val)\n",
    "            query_words_index[min_val_pos] += 1\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_text_to_words(text):\n",
    "        # 使用正则表达式去除标点符号和换行符\n",
    "        text = re.sub(r'[^\\w ]', ' ', text)\n",
    "        # 转为小写\n",
    "        text = text.lower()\n",
    "        # 生成所有单词的列表\n",
    "        word_list = text.split(' ')\n",
    "        # 去除空白单词\n",
    "        word_list = filter(None, word_list)\n",
    "        # 返回单词的 set\n",
    "        return set(word_list)\n",
    "\n",
    "search_engine = BOWInvertedIndexEngine()\n",
    "main(search_engine)\n",
    "\n",
    "\n",
    "########## 输出 ##########\n",
    "\n",
    "\n",
    "# little\n",
    "# found 2 result(s):\n",
    "# 1.txt\n",
    "# 2.txt\n",
    "# little vicious\n",
    "# found 1 result(s):\n",
    "# 2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新模型继续使用之前的接口，仍然只在 __init__()、process_corpus()和search()三个函数进行修改。\n",
    "\n",
    "<font color=red>这其实也是大公司里团队协作的一种方式，在合理的分层设计后，每一层的逻辑只需要处理好分内的事情即可。在迭代升级我们的搜索引擎内核时， main 函数、用户接口没有任何改变。当然，如果公司招了新的前端工程师，要对用户接口部分进行修改，新人也不需要过分担心后台的事情，只要做好数据交互就可以了。</font>\n",
    "\n",
    "1. 针对第一个问题，我们采用倒序索引\n",
    "倒序索引，一如其名，也就是说这次反过来，我们保留的是 word -> id 的字典。于是情况就豁然开朗了，在 search 时，我们只需要把想要的 query_word 的几个倒序索引单独拎出来，然后从这几个列表中找共有的元素，那些共有的元素，即 ID，就是我们想要的查询结果。这样，我们就避免了将所有的 index 过一遍的尴尬。\n",
    "\n",
    "process_corpus 建立倒序索引。注意，这里的代码都是非常精简的。在工业界领域，需要一个 unique ID 生成器，来对每一篇文章标记上不同的 ID，倒序索引也应该按照这个 unique_id 来进行排序。\n",
    "\n",
    "至于 search() 函数，你大概了解它做的事情即可。它会根据 query_words 拿到所有的倒序索引，如果拿不到，就表示有的 query word 不存在于任何文章中，直接返回空；拿到之后，运行一个“合并 K 个有序数组”的算法，从中拿到我们想要的 ID，并返回。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
